{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd00decfbe5a70d8910007bbce8687584085ed75017321d767c169c5dae039dd627",
   "display_name": "Python 3.6.13 64-bit ('vgm-tf-keras-gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Notes and Resources\n",
    "* Towards data science tutorial\n",
    "    * https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "* Encompassing tutorial\n",
    "    * https://www.datacamp.com/community/tutorials/using-tensorflow-to-compose-music\n",
    "* LSTM for Time Series\n",
    "    * https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n",
    "* Model Checkpoint and Early Stopping\n",
    "    * https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "* Tips for Improving RNNs\n",
    "    * https://danijar.com/tips-for-training-recurrent-neural-networks/\n",
    "* Alternative form of labeling for efficiency and scalability?\n",
    "    * https://datascience.stackexchange.com/questions/24729/one-hot-encoding-alternatives-for-large-categorical-values\n",
    "\n",
    "# Framing the problem\n",
    "Generation of music is a multiclass classification problem because a unique chord may be represented by a one-hot vector of chords where the length of the one-hot vector is the 'musical space' (vocab) of the particular classification problem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "\n",
    "# MIDI processing\n",
    "from music21 import *\n",
    "\n",
    "# Tensorflow and Keras\n",
    "import tensorflow.keras as keras\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Wrangling\n",
    "import numpy as np\n",
    "\n",
    "# Visual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Misc\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string_to_chord(concatenated_chord):\n",
    "    \"\"\"Convert a concatenated chord to list of notes for music21 chord.\n",
    "    \n",
    "    :param concatenated_chord: <class 'str'>  A concatenated string\n",
    "        representing a string.\n",
    "    :return: <class 'list'> A list of strings representing a chord\n",
    "        for music21\n",
    "    \"\"\"\n",
    "    chord = []\n",
    "    slice_from = 0\n",
    "    for ix, char in enumerate(concatenated_chord):\n",
    "        if char.isdigit():\n",
    "            chord.append(concatenated_chord[slice_from:ix + 1])\n",
    "            slice_from = ix + 1\n",
    "\n",
    "    # Return list of notes (a chord)\n",
    "    return chord\n",
    "\n",
    "\n",
    "def generate_music21_stream_from_int_chords(chord_list, mapping, instrument_part=None):\n",
    "    \"\"\"Convert a list of chords to a music21 stream.\n",
    "    \n",
    "    :param chord_list: Array like list of integer chords\n",
    "        chords to be converted to music21 stream.\n",
    "    :param mapping: <class 'dict'> that maps integer chords to \n",
    "        string chords.\n",
    "    :param instrument: <class 'music21.instrument.Instrument'> Defaults\n",
    "        to KeyboardInstrument()\n",
    "    :return: <class 'music21.stream.Part'>\n",
    "    \"\"\"\n",
    "\n",
    "    # Default instrument\n",
    "    if (not instrument_part):\n",
    "        instrument_part = instrument.KeyboardInstrument()\n",
    "\n",
    "    # Map to string list\n",
    "    chord_list = [mapping[chord] for chord in chord_list]\n",
    "\n",
    "    ## Make stream\n",
    "    # Generate stream with piano as instrument\n",
    "    generated_stream = stream.Part()\n",
    "    generated_stream.append(instrument_part)\n",
    "\n",
    "    # Append notes to stream\n",
    "    for single_chord in chord_list:\n",
    "        try:\n",
    "            generated_stream.append(note.Note(single_chord))\n",
    "        except:\n",
    "            extracted_chord = parse_string_to_chord(single_chord)\n",
    "            generated_stream.append(chord.Chord(extracted_chord))\n",
    "\n",
    "\n",
    "    # Return the music21 stream\n",
    "    return generated_stream"
   ]
  },
  {
   "source": [
    "# Loading and preprocessing data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['chords_ds', 'durations_ds', 'chord_to_int', 'duration_to_int', 'int_to_chord', 'int_to_duration'])\n"
     ]
    }
   ],
   "source": [
    "# Load feature and encoding data\n",
    "path_to_pickled_data = '../../pickled_data/pickled_tentatively_transposed_feature_and_encoding_dict'\n",
    "# with open(os.path.join(path_to_pickled_data, 'pickled_feature_and_encoding_dict'),'rb') as fobj:\n",
    "#     data_dict = pickle.load(fobj)\n",
    "\n",
    "with open(path_to_pickled_data, 'rb') as fobj:\n",
    "    data_dict = pickle.load(fobj)\n",
    "\n",
    "# Get Data\n",
    "print(data_dict.keys())\n",
    "chords_ds = data_dict['chords_ds']\n",
    "durations_ds = data_dict['durations_ds']\n",
    "chord_to_int = data_dict['chord_to_int']\n",
    "duration_to_int = data_dict['duration_to_int']\n",
    "int_to_chord = data_dict['int_to_chord']\n",
    "int_to_duration = data_dict['int_to_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['C4E4A4', 'C4E4G4', 'A3C4F#4', 'E3A3', 'E3B3', 'A3C4', 'A3D4', 'A3C4E4', 'C3F3A3', 'F3A3E4']\nFlattend chords_ds type is <class 'str'>? True\nFlattend chords_ds length: 25140\nUnique notes/chords 1759\n"
     ]
    }
   ],
   "source": [
    "# Flatten list\n",
    "chords_ds_flattened = [item for sublist in chords_ds for item in sublist]\n",
    "print(chords_ds_flattened[:10])\n",
    "print(\"Flattend chords_ds type is <class 'str'>?\", all(isinstance(x, str) for x in chords_ds_flattened))\n",
    "print('Flattend chords_ds length:', len(chords_ds_flattened))\n",
    "print('Unique notes/chords', len(chord_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 243 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "## Defining training data -- previous sequential data\n",
    "\n",
    "# Dimensions for LSTM\n",
    "n_sequence_patterns = None  # number of samples\n",
    "n_vocab = len(np.unique(chords_ds_flattened))  # Unique categories for a given sample \n",
    "sequence_length = 100        # Number of time steps in a sample\n",
    "num_features = 1    # Number of a features a given sample vector has (in this case only 1 feature which is an integer representing a chord/note)\n",
    "\n",
    "# Empty lists for train data\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "## Sequence construction\n",
    "# The chord_ds encapsulates the chords/notes associated with a particular score index\n",
    "# create input sequences and the corresponding outputs\n",
    "for i in range(0, len(chords_ds_flattened) - sequence_length):\n",
    "    chord_sequence_input = chords_ds_flattened[i:i + sequence_length]  # i to the i + sequence length (exclusive) input\n",
    "    chord_sequence_output = chords_ds_flattened[i + sequence_length]   # the i + sequence length output (next note after a sequence of notes)\n",
    "    network_input.append([chord_to_int[chord] for chord in chord_sequence_input])\n",
    "    network_output.append(chord_to_int[chord_sequence_output])\n",
    "\n",
    "# Update number of sequence patterns based on network_input\n",
    "n_sequence_patterns = len(network_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Input shape:'"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "(25040, 100, 1)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Sample input sequence (i.e. of shape (1 sample, t=5 out of 100 timesteps, 1 feature -- the chord)):'"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[0.40250142],\n       [0.40534395],\n       [0.14837976],\n       [0.72143263],\n       [0.72768619]])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Output shape:'"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "(25040, 1759)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'The expected note after the preceding 100 notes:'"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "## Shape the input for LSTM (which take (?, t_timesteps, f_features)) where ? is the number of samples (pattern sequences)\n",
    "network_input = np.reshape(network_input, (n_sequence_patterns, sequence_length, 1))\n",
    "network_input = network_input / float(n_vocab)  # Divide each element of integer network array by n_vocab = 202 to normalize the input\n",
    "\n",
    "# Inspect the input\n",
    "display('Input shape:', network_input.shape)\n",
    "display(f'Sample input sequence (i.e. of shape (1 sample, t=5 out of {sequence_length} timesteps, 1 feature -- the chord)):', network_input[0][:5])\n",
    "\n",
    "## One-hot label categorical data\n",
    "network_output = keras.utils.to_categorical(network_output, num_classes=n_vocab)\n",
    "\n",
    "# Inspect output\n",
    "display('Output shape:', network_output.shape)\n",
    "display(f'The expected note after the preceding {sequence_length} notes:', network_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train-test/Holdout validation array:\n(20032, 100, 1)\n(20032, 1759)\n(5008, 100, 1)\n(5008, 1759)\n\nTrain/Test Arrays:\n(16025, 100, 1)\n(16025, 1759)\n(4007, 100, 1)\n(4007, 1759)\n\nn_vocab: 1759\n"
     ]
    }
   ],
   "source": [
    "### Divide sets\n",
    "## X_holdout_validation and y_holdout_validation are not used until a model is optimized\n",
    "X_train_test, X_holdout_validation, y_train_test, y_holdout_validation = train_test_split(\n",
    "    network_input,\n",
    "    network_output, \n",
    "    random_state=0, \n",
    "    shuffle=False,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "# Inspect after sklearn function\n",
    "print('Train-test/Holdout validation array:')\n",
    "print(X_train_test.shape)\n",
    "print(y_train_test.shape)\n",
    "print(X_holdout_validation.shape)\n",
    "print(y_holdout_validation.shape)\n",
    "\n",
    "## Train test split (test will be used for validation=[] for hyperparam optimization)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_test,\n",
    "    y_train_test, \n",
    "    random_state=0, \n",
    "    shuffle=False,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "# Inspect now\n",
    "print()\n",
    "print('Train/Test Arrays:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Check n_vocab\n",
    "print()\n",
    "print('n_vocab:',n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the model\n",
    "\n",
    "# On LSTM crashing\n",
    "# https://github.com/tensorflow/tensorflow/issues/37942\n",
    "\n",
    "# Hyperparameters\n",
    "lstm_hidden_units = 512\n",
    "dense_hidden_units = 256\n",
    "batch_size = 128\n",
    "epochs = 256\n",
    "\n",
    "# Save current time\n",
    "now = datetime.now().strftime('%Y%m%d_%H-%M-%S')\n",
    "\n",
    "# Instantiate the sequential model\n",
    "name = f'{now}_lstm'\n",
    "model = keras.models.Sequential(name=name)\n",
    "\n",
    "# Input layer\n",
    "model.add(\n",
    "    keras.layers.LSTM(\n",
    "        lstm_hidden_units,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        recurrent_dropout=0.3,\n",
    "        return_sequences=True,\n",
    "        name='input_lstm'\n",
    "))\n",
    "\n",
    "# LSTM hidden 0\n",
    "model.add(keras.layers.LSTM(lstm_hidden_units, return_sequences=True, recurrent_dropout=0.3))\n",
    "\n",
    "# LSTM hidden 1\n",
    "model.add(keras.layers.LSTM(lstm_hidden_units))\n",
    "\n",
    "# Batch norm\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# Dropout\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "# ## Dense\n",
    "# model.add(keras.layers.Dense(dense_hidden_units,))\n",
    "# model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "# # Batch norm\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# # Dropout\n",
    "# model.add(keras.layers.Dropout(0.3,))\n",
    "\n",
    "## Output\n",
    "model.add(keras.layers.Dense(n_vocab, activation='softmax', name='dense_output'))\n",
    "\n",
    "# Compile it\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# Display it \n",
    "keras.utils.plot_model(model, to_file=f'./figures/{now}_lstm.png', expand_nested=True, show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jared\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Attempted to save a function b'__inference_input_lstm_layer_call_fn_13637' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 512), dtype=float32) that is not a simple constant. This is not supported.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7efa9cfcd045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the untrained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./untrained_models/{now}_lstm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \"\"\"\n\u001b[0;32m   1007\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1008\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    113\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[1;32m--> 115\u001b[1;33m                           signatures, options)\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m# we use the default replica context here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m       \u001b[0msave_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m    907\u001b[0m   \u001b[0mobject_saver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrackableSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m   asset_info, exported_graph = _fill_meta_graph_def(\n\u001b[1;32m--> 909\u001b[1;33m       meta_graph_def, saveable_view, signatures, options.namespace_whitelist)\n\u001b[0m\u001b[0;32m    910\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[0;32m    911\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36m_fill_meta_graph_def\u001b[1;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist)\u001b[0m\n\u001b[0;32m    551\u001b[0m   \u001b[0mresource_initializer_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mexported_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m     \u001b[0mobject_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masset_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_resources\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mresource_initializer_function\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresource_initializer_functions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m       \u001b[0masset_dependencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36mmap_resources\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m                 (\"Attempted to save a function {} which references a symbolic \"\n\u001b[0;32m    284\u001b[0m                  \u001b[1;34m\"Tensor {} that is not a simple constant. This is not \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m                  \"supported.\").format(concrete_function.name, capture))\n\u001b[0m\u001b[0;32m    286\u001b[0m           \u001b[0mcopied_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapture_constant_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m           \u001b[0mnode_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempted to save a function b'__inference_input_lstm_layer_call_fn_13637' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 512), dtype=float32) that is not a simple constant. This is not supported."
     ]
    }
   ],
   "source": [
    "# Save the untrained model\n",
    "#model.save(f'./untrained_models/{now}_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 16025 samples\n",
      "Epoch 1/256\n",
      "  128/16025 [..............................] - ETA: 11:52"
     ]
    },
    {
     "output_type": "error",
     "ename": "InternalError",
     "evalue": " Blas GEMM launch failed : a.shape=(128, 1), b.shape=(1, 512), m=128, n=512, k=1\n\t [[{{node 20210424_10-34-07_lstm/input_lstm/while/body/_1/MatMul}}]] [Op:__inference_distributed_function_24813]\n\nFunction call stack:\ndistributed_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\vgm-tf-keras-gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Blas GEMM launch failed : a.shape=(128, 1), b.shape=(1, 512), m=128, n=512, k=1\n\t [[{{node 20210424_10-34-07_lstm/input_lstm/while/body/_1/MatMul}}]] [Op:__inference_distributed_function_24813]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Fitting the model\n",
    "## Callbacks\n",
    "fit = True\n",
    "if (fit):\n",
    "    checkpoint = ModelCheckpoint(f'./saved_models_h5/{now}_best_model.h5', monitor='loss', mode='min', save_best_only=True, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='loss', verbose=1, patience=32)\n",
    "    #log_dir = \"logs\\\\fit\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    #tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    ## Training\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        #callbacks=[checkpoint, early_stopping],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model history\n",
    "with open(f'./history/pickled_{now}_history', 'wb') as fobj\n",
    "    pickle.dump(history ,fobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model if possible\n",
    "if (not fit):\n",
    "    model = keras.models.load_model('./saved_models_h5/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100, 1)\n[[ 629]\n [1164]\n [1164]\n [1164]\n [1399]\n [1164]\n [1164]\n [1164]\n [1164]\n [1164]\n [1164]\n [1399]\n [ 629]\n [ 629]\n [1059]\n [ 629]\n [1399]\n [1059]\n [1399]\n [1403]\n [1403]\n [1164]\n [1164]\n [1164]\n [1399]\n [ 629]\n [ 629]\n [ 629]\n [1164]\n [1164]\n [1164]\n [1399]\n [1164]\n [1164]\n [1164]\n [1164]\n [1164]\n [1164]\n [1399]\n [ 629]\n [ 629]\n [1059]\n [ 629]\n [1399]\n [1059]\n [1399]\n [1403]\n [1403]\n [1164]\n [1059]\n [1164]\n [1399]\n [ 629]\n [1059]\n [1399]\n [ 629]\n [1164]\n [1399]\n [ 629]\n [1059]\n [1399]\n [1399]\n [1164]\n [1059]\n [1164]\n [1399]\n [ 629]\n [1059]\n [1399]\n [ 629]\n [1164]\n [1399]\n [ 629]\n [1059]\n [1399]\n [1399]\n [1164]\n [1059]\n [1164]\n [1399]\n [ 629]\n [1059]\n [1399]\n [ 629]\n [1164]\n [1399]\n [ 629]\n [1059]\n [1399]\n [1399]\n [1399]\n [1059]\n [1059]\n [1399]\n [1059]\n [1059]\n [1399]\n [1059]\n [1059]\n [1399]]\n"
     ]
    }
   ],
   "source": [
    "# Take random starting from test set () not holdout validation set\n",
    "random_ix_of_sequence_elem_in_x_test = np.random.randint(0, X_test.shape[0])\n",
    "chord_sequence = X_test[random_ix_of_sequence_elem_in_x_test]\n",
    "original_sequence = chord_sequence.copy()\n",
    "\n",
    "# Inspect chord_sequence\n",
    "print(original_sequence.shape)\n",
    "print((original_sequence * n_vocab).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Store predictions\n",
    "prediction_output = [] # generate desired number of notes/chords\n",
    "for note_index in range(64):\n",
    "\n",
    "    # Reshape the input for the network (?, sequence_length=..., 1 feature (a chord))\n",
    "    prediction_input = np.reshape(chord_sequence, (1, sequence_length, 1))\n",
    "\n",
    "    # Generate (sequence_length, 1) dimensional song \n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "    # The index of the argmax of the prediction is the chord (feature) with\n",
    "    # highest probability of being classified (making logical music) due to\n",
    "    # softmax activation    \n",
    "    index = np.argmax(prediction)\n",
    "\n",
    "    # Map the result to a chord\n",
    "    result = int_to_chord[index]\n",
    "\n",
    "    # Append that chord to a list of predicted chords\n",
    "    prediction_output.append(result)    \n",
    "    \n",
    "    # Convert the result into a normalized value and append it to the existing chord_sequence\n",
    "    chord_sequence = np.append(chord_sequence, (index / float(n_vocab)))\n",
    "\n",
    "    # After the first prediction, the chord_sequence now hold 33 notes\n",
    "    # Keep only the next set of notes (i.e., notes 1-33) instead of notes (0-32)\n",
    "    # Sliding window prediction...\n",
    "    chord_sequence = chord_sequence[1:len(chord_sequence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([115, 172, 172,  42, 172,  42, 172, 115, 172, 172,  42,  42, 172,\n",
       "       115, 172, 172,  42, 172,  42, 172, 115, 115, 115, 163, 163, 163,\n",
       "       163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 189, 189, 189,\n",
       "       189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189,\n",
       "       189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189,\n",
       "       189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189,\n",
       "       189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189,\n",
       "       189, 189, 189, 189, 189, 189, 189, 189, 189])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Convert the chord_sequence back to integers\n",
    "chord_sequence = (chord_sequence * n_vocab).astype(int)\n",
    "chord_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated song\n",
    "generated_song = generate_music21_stream_from_int_chords(chord_sequence, mapping=int_to_chord)\n",
    "\n",
    "# Save the original song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20210422_23-18-57\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'./generated_songs/20210422_23-18-57_generated_song.mid'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Save the generated song\n",
    "print(now)\n",
    "if (not fit):\n",
    "    now = datetime.now().strftime('%Y%m%d_%H-%S-%M')\n",
    "generated_song.write('midi', f'./generated_songs/{now}_generated_song.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}